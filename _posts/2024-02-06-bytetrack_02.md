---
layout: single
title:  "ByteTrack (02) - 논문 리뷰 part 2"
categories: 
    - AI
tag:
    - [deep learning, review, computer vision, object tracking, bytetrack]    
author_profile: false
sidebar:
    nav: "docs"
use_math: true
---
> ECCV 2022. [[Paper](https://arxiv.org/abs/2110.06864)] [[Github](https://github.com/ifzhang/ByteTrack)]  
> Zhang, YiFu, et al.
> Huazhong University of Science and Techonology  
> 7 Apr 2022  


## Introduction
저번 포스팅에 이어 ByteTrack 리뷰를 계속하고자 한다.  
이번 포스팅에서는 ByteTrack의 알고리즘을 메인으로 리뷰한다.
다시 한번 논문의 제목이 ByteTrack: Multi-Object Tracking by Associating Every Detection Box 임을 상기하고 가자.  

## Datasets / Detector
ByteTrack에서는 여러 데이터셋을 사용했는데 기본적으로 bytetrack은 IOU 기반 방식이므로 tracking에 대한 학습이 필요하지는 않다. 다만 detection 기반으로 tracking을 수행하므로 detector를 훈련시키기 위한 데이터셋이 필요하다.
- MOT17 : tracking 전용 데이터셋, 학습 및 테스트 사용
- MOT20 : tracking 전용 데이터셋, 학습 및 테스트 사용
- CrowdHuman : detector 학습만
- Cityperson : detector 학습만
- BDD100K : 자율주행 데이터셋, 테스트만 사용

물체를 찾기 위한 detector로는 coco 데이터셋에서 사전학습된 가중치로 학습시킨 YOLOX-X모델을 사용하였다. 참고로 mosaic와 mixup은 yolo 시리즈에서 많이 사용되는 증강 기법으로 mosaic는 이미지를 잘라서 2x2 or 3x3의 형태로 붙이는 기법이고 mixup은 이미지를 선형적으로 결합하는 기법이다.  
- epoch: 50
- 증강 기법: Mosaic와 Mixup 기법이 포함
- GPU : Tesla V100 GPU * 8
- optimizer: SGD(momentum=0.9), weight decay $5\times10^{-4}$
- learning rate: $10^{-3}$, cosine annealing schedule

## Methods
이제 ByteTrack의 알고리즘을 살펴보자.  
첨부된 아래의 그림을 참고하면 이해가 쉽다.  
<center><img src='{{"/assets/images/post-bytetrack/bytetrack01.PNG" | relative_url}}' width="90%"></center>
<br>
<center><img src='{{"/assets/images/post-bytetrack/bytetrack02.PNG" | relative_url}}' width="90%"></center>
<br>
Tracking 알고리즘의 고질적인 문제점은 물체 간 폐색(occlusion; 가려짐)이 발생 시 tracking의 성능이 떨어지는 것이다.  
그도 그럴 것이 물체간 폐색이 일어나면 가려진 물체의 경우 confidence score가 낮아지게 되고 tracking에서 제외하게 된다.  
ByteTrack은 이러한 경우에 바로 제외하지 않고 두 번의 association을 통해 tracking 성능을 보완하고자 하는 것이다.  

* Association : Tracklet과 detection box를 비교하여 유사성을 기반으로 매칭시키는 것  

Pseduo-code of BYTE를 살펴보자.  
먼저 입력으로 영상이 필요하고 detection에 기반한 tracking이므로 detector역시 필요하다. 그리고 임의로 설정 가능한 임계값 $\tau$ 가 필요하다.  
원하는 출력은 video의 track이 될 것이다.  
* 1번 라인에서는 Track을 초기화한다. 이것은 초기 실행시에만 수행한다.  
* 2~13 라인은 반복문인데 영상의 프레임마다 detector에 입력으로 넣어준다. 이때 예측된 box의 confidence score가 $\tau$보다 크다면 $D_{high}$에 저장하고 그렇지않으면 $D_{low}$에 저장한다.
* 14~16 라인은 이전 프레임에서의 track에 칼만 필터를 적용하여 현재 프레임의 박스를 예측한다.
* 17~19 라인은 first association에 해당하며 유사성을 계산하여 $T$와 $D_{high}$를 매칭시킨다. 유사성은 Re-ID기반으로 할 수도 있고 IOU 기반으로도 할 수 있다. 매칭이 되지 않은 $D_{high}$ 박스들은 $D_{remain}$에 저장한다. 마찬가지로 매칭되지 않은 track들은 $T_{remain}$에 저장한다.
* 20~22 라인은 second association에 해당하며 $T_{remain}$과 $D_{low}$를 비교하여 매칭하고 여기에서도 매칭이 되지 않을 경우에는 track에서 제거한다. \기호는 차집합을 의미한다.
* 23~27 라인은 $D_{remain}$에 대해 수행하고 최종적으로 매칭에 성공한 track을 반환한다.

그림을 보면서 예시를 보면 (a)는 detection box를 나타낸 그림인데 $t_{2}$ 시점에서 폐색이 일어나 score가 낮아지는 것을 볼 수 있다. (b)는 threshold는 0.5로 가정했을 때의 hight score detection 박스들을 association한 tracklet이다. $t_{1}$에서의 사람은 초록색 빨간색 파란색 사람이 track이 시작되나 칼만필터 적용 이후 $t_{2}$ 시점에서의 detection과 비교해 보면 빨간색 사람은 잡을 수 없다. (c)는 모든 detection 박스를 association했을 때의 결과인데 이때는 빨간색 박스의 사람은 occlusion이 일어나 score가 낮아졌으나 second association을 통해 매칭이 가능하다. 우측에 0.1 score를 가진 박스의 경우 score가 낮아 track이 시작되지 않는다. 물론 알고리즘상 예상할 수 있는 문제점을 생각해 보자면 실제 높은 score를 가진 사람이 0.1 박스 위치에 있었다가 빠르게 없어졌을 경우에는 0.1 박스 위치를 계속 tracking할 수 있다.  
대략적인 원리는 이렇고 실제 적용에서는 detector의 성능에 따라 검출을 하지 못할 수도 있기 때문에 일정 수의 frame (ex. 30frame)까지는 남겨두고 다음 track이 시작될때 합쳐 주는 등의 디테일이 포함되어 있다. 또한 0.1박스와 같은 사례를 방지하기 위해 low threshold의 도입을 통해 너무 낮은 score를 가진 box의 경우 애초에 제거해버린다.

___
여기까지 bytetrack 알고리즘을 살펴보았고 다음 포스팅에서 평가지표와 실험 결과에 대해 리뷰하도록 하자.


